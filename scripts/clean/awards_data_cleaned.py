#!/usr/bin/env python
"""
Clean every raw award CSV in data/raw/awards/ and write
a cleaned, longâ€format version to data/processed/awards/<stem>_cleaned.csv.

Special handling:
  â€¢ If a CSV has columns like "Unnamed: 4", "Unnamed: 5", â€¦, these
    are treated as â€œextra playerâ€ columns. We melt them into a single
    'player' column so each player occupies its own row.

Output for each file:
  data/processed/awards/<stem>_cleaned.csv
"""
from pathlib import Path
import sys
import re

import pandas as pd

# â”€â”€ PROJECT ROOT & IMPORT HELPERS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROOT = Path(__file__).resolve().parents[2]
sys.path.append(str(ROOT))
# Ensure utils package is recognized
(ROOT / "utils" / "__init__.py").touch(exist_ok=True)

from utils.clean_helpers import normalise_cols

# â”€â”€ RAW / PROCESSED DIRECTORIES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
RAW_DIR  = ROOT / "data" / "raw" / "awards"
PROC_DIR = ROOT / "data" / "processed" / "awards"

# Ensure the processed/awards directory exists
PROC_DIR.mkdir(parents=True, exist_ok=True)


def clean_award_csv(input_path: Path, output_path: Path, award_name: str) -> None:
    """
    1. Read a single raw award CSV (input_path)
    2. Normalize & rename columns
    3. Detect any â€œUnnamed: â€¦â€ columns and melt them into a single 'player' column
    4. Add an "award" column (award_name)
    5. Convert numeric columns (excluding award, player, etc.)
    6. Split 'season' into season_start/season_end
    7. Tidy text fields (team, player)
    8. Drop exact duplicates
    9. Write cleaned CSV to output_path
    """

    # â”€â”€ 1) CHECK INPUT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if not input_path.exists() or not input_path.is_file():
        raise FileNotFoundError(f"Input CSV not found: {input_path}")

    # â”€â”€ 2) LOAD â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df = pd.read_csv(input_path)
    print(f"\nğŸ“¥ Loaded {len(df)} rows from '{input_path.name}'.")

    # â”€â”€ 3) NORMALIZE & RENAME EXISTING COLUMNS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df.columns = normalise_cols(df.columns)

    # Rename 'tm' â†’ 'team' if present
    if "tm" in df.columns:
        df.rename(columns={"tm": "team"}, inplace=True)

    # If a â€œ9999â€ column exists (as in some previous MVP code), rename it to 'player_id'
    if "9999" in df.columns:
        df.rename(columns={"9999": "player_id"}, inplace=True)

    # Drop any unwanted columns like 'voting' if present
    df = df.drop(columns={"voting"}, errors="ignore")

    # â”€â”€ 4) HANDLE MULTIPLE â€œUnnamed: â€¦â€ COLUMNS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Find all columns whose name matches r"^unnamed:\s*\d+$" (caseâ€insensitive).
    unnamed_pattern = re.compile(r"^unnamed:\s*\d+$", flags=re.IGNORECASE)
    unnamed_cols = [c for c in df.columns if unnamed_pattern.match(c)]

    if unnamed_cols:
        print(f"ğŸ” Found {len(unnamed_cols)} Unnamed playerâ€columns: {unnamed_cols}")

        # We assume the other columns (besides unnamed_cols) should be kept as-is.
        other_cols = [c for c in df.columns if c not in unnamed_cols]

        # Melt: each â€œUnnamed: Xâ€ becomes its own row under a new 'player' column.
        df = (
            df
            .melt(
                id_vars=other_cols,
                value_vars=unnamed_cols,
                var_name="member_rank",
                value_name="player"
            )
            .drop(columns=["member_rank"])  # we donâ€™t need the original â€œUnnamedâ€ label
            .loc[lambda d: d["player"].notna()]  # drop any rows where player was NaN
            .reset_index(drop=True)
        )
        print(f"ğŸ”„ After melting, {len(df)} total rows (one per player).")
    else:
        # If there are no â€œUnnamed: Xâ€ columns, ensure at least one 'player' column exists
        if "player" not in df.columns:
            # It's possible the CSV is already single-player-per-row. We trust that.
            print("â„¹ï¸ No 'player' column found and no Unnamed columns. Leaving as-is.")

    # â”€â”€ 5) ADD AWARD NAME COLUMN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    df["award"] = award_name

    # â”€â”€ 6) NUMERIC CONVERSION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Treat the following as text, never coerce to numeric:
    text_cols = ["season", "lg", "player", "team", "player_id", "award"]
    existing_text_cols = [c for c in text_cols if c in df.columns]
    numeric_cols = df.columns.difference(existing_text_cols)

    # Convert all other columns to numeric (NaN if not parseable)
    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors="coerce")
    print(f"ğŸ”¢ Converted to numeric (excluding text cols): {list(numeric_cols)}")

    # â”€â”€ 7) SPLIT 'season' â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "season" in df.columns:
        # Handle "YYYY-YY" or "YYYYâ€“YY" (en dash) by extracting the first 4 digits
        df["season_start"] = df["season"].str.extract(r"^(\d{4})", expand=False).astype(int)
        df["season_end"] = df["season_start"] + 1
    else:
        print("âš ï¸ 'season' column missing; skipping season_start/season_end.")

    # â”€â”€ 8) TIDY TEXT FIELDS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if "team" in df.columns:
        df["team"] = df["team"].fillna("").str.strip().replace("", "FA")
    if "player" in df.columns:
        df["player"] = df["player"].str.strip()

    # â”€â”€ 9) DROP EXACT DUPLICATES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    before = len(df)
    df = df.drop_duplicates()
    dropped = before - len(df)
    print(f"ğŸ—‘ï¸ Dropped {dropped} exact duplicate rows (if any). Total now: {len(df)}.")

    # â”€â”€ 10) SAVE CLEANED CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    try:
        df.to_csv(output_path, index=False)
        print(f"âœ… Saved cleaned data to: {output_path.name}")
    except PermissionError as e:
        raise PermissionError(
            f"Cannot write to '{output_path}'. Is it open or read-only?"
        ) from e


if __name__ == "__main__":
    # â”€â”€ LOOP OVER EVERY CSV IN RAW_DIR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    csv_files = sorted(RAW_DIR.glob("*.csv"))
    if not csv_files:
        print(f"âš ï¸ No CSV files found in {RAW_DIR}. Nothing to clean.")
        sys.exit(0)

    for input_path in csv_files:
        stem = input_path.stem.lower()

        # â”€â”€ SKIP any â€œall_*_teamsâ€ files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # If the filename stem starts with "all_" and ends with "_teams",
        # we skip it entirely:
        if stem.startswith("all_") and stem.endswith("_teams"):
            print(f"âš ï¸ Skipping all_*teams file: '{input_path.name}'")
            continue

        # Derive award_name from the filename stem (e.g. "roty", "mvp", etc.)
        award_name = stem

        # Output filename: "<stem>_cleaned.csv"
        output_name = f"{stem}_cleaned.csv"
        output_path = PROC_DIR / output_name

        print(f"\nğŸ”„ Cleaning '{input_path.name}' â†’ '{output_name}' (award='{award_name}')")
        clean_award_csv(
            input_path=input_path,
            output_path=output_path,
            award_name=award_name
        )
